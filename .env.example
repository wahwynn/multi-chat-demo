# Backend Environment Variables
# Copy this file to .env and fill in your values

# Anthropic API Key (REQUIRED)
# Get your API key from https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Ollama Base URL (OPTIONAL)
# Default: http://localhost:11434
# Only needed if using Ollama models or if Ollama is running on a different host/port
# OLLAMA_BASE_URL=http://localhost:11434

# Chat Context Window Size (OPTIONAL)
# Default: 10
# Number of recent messages to include in context when sending to AI models
# CHAT_CONTEXT_WINDOW_SIZE=10
